# server.py - è”é‚¦å­¦ä¹ æœåŠ¡å™¨
from flask import Flask, request, jsonify
import torch
import torch.nn as nn
import json
import os
import time
from datetime import datetime
from pathlib import Path
import traceback
import copy

# å¯¼å…¥é…ç½®
from config import config

app = Flask(__name__)

# æ¨¡å‹å®šä¹‰
class DiabeticRetinopathyModel(nn.Module):
    """ä¸Kaggleé¡¹ç›®åŒ¹é…çš„ç®€åŒ–CNNæ¨¡å‹"""
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(128, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, config.get("model.num_classes", 5))
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# æœåŠ¡å™¨çŠ¶æ€ç®¡ç† 
class ServerState:
    """ç®¡ç†æœåŠ¡å™¨çŠ¶æ€"""
    def __init__(self):
        self.global_model = DiabeticRetinopathyModel()
        self.client_updates = []  # å­˜å‚¨å®¢æˆ·ç«¯æ›´æ–°
        self.client_ids = []      # è®°å½•å·²æäº¤çš„å®¢æˆ·ç«¯
        self.round_num = 0
        self.start_time = time.time()
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        self.save_path = Path(config.get("server.model_save_path", "./saved_models"))
        self.save_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
        self.load_latest_checkpoint()
    
    def load_latest_checkpoint(self):
        """åŠ è½½æœ€æ–°çš„æ¨¡å‹æ£€æŸ¥ç‚¹"""
        checkpoints = list(self.save_path.glob("global_model_round_*.pth"))
        if checkpoints:
            latest = max(checkpoints, key=lambda x: int(x.stem.split('_')[-1]))
            self.global_model.load_state_dict(torch.load(latest))
            self.round_num = int(latest.stem.split('_')[-1])
            print(f"âœ… åŠ è½½æ£€æŸ¥ç‚¹: {latest.name} (è½®æ¬¡ {self.round_num})")
    
    def save_checkpoint(self):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        filename = self.save_path / f"global_model_round_{self.round_num}.pth"
        torch.save(self.global_model.state_dict(), filename)
        
        # åŒæ—¶ä¿å­˜ä¸ºæœ€æ–°ç‰ˆæœ¬
        latest_path = self.save_path / "global_model_latest.pth"
        torch.save(self.global_model.state_dict(), latest_path)
        
        print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {filename.name}")
    
    def add_client_update(self, client_id, update):
        """æ·»åŠ å®¢æˆ·ç«¯æ›´æ–°"""
        if client_id not in self.client_ids:
            self.client_updates.append({
                'client_id': client_id,
                'weights': update,
                'timestamp': time.time()
            })
            self.client_ids.append(client_id)
            return True
        return False  # å®¢æˆ·ç«¯å·²æäº¤
    
    def reset_round(self):
        """é‡ç½®è½®æ¬¡çŠ¶æ€"""
        self.client_updates = []
        self.client_ids = []
    
    def federated_average(self):
        """
        FIXED (Final Version): Correctly extracts 'weights' from the dictionary envelope.
        """

        if len(self.client_updates) < self.min_clients:
            return False

        print(f"ğŸ”„ Aggregating updates from {len(self.client_updates)} clients...")

        first_client_update_wrapper = self.client_updates[0]
        first_client_weights = first_client_update_wrapper['weights'] 
        
        avg_weights = copy.deepcopy(first_client_weights)


        for i in range(1, len(self.client_updates)):
            client_wrapper = self.client_updates[i]
            client_weights = client_wrapper['weights'] # <--- Extract weights here too
            
            for key in avg_weights:
                # Accumulate the tensors
                avg_weights[key] += client_weights[key]

        num_clients = len(self.client_updates)
        for key in avg_weights:
            avg_weights[key] = avg_weights[key].float() / num_clients

        self.global_model.load_state_dict(avg_weights)
        self.save_model()
        
        self.client_updates = []
        self.current_round += 1
        print(f"âœ… Round {self.current_round} complete. Global model updated.")
        
        return True

# åˆå§‹åŒ–æœåŠ¡å™¨çŠ¶æ€
server_state = ServerState()

# Flaskè·¯ç”± 
@app.route('/')
def home():
    """æœåŠ¡å™¨çŠ¶æ€é¡µ"""
    uptime = time.time() - server_state.start_time
    return jsonify({
        "status": "running",
        "round": server_state.round_num,
        "uptime_seconds": int(uptime),
        "clients_registered": len(server_state.client_ids),
        "model_info": {
            "name": "DiabeticRetinopathyModel",
            "input_size": config.get("model.input_size", 224),
            "num_classes": config.get("model.num_classes", 5)
        }
    })

@app.route('/get_model', methods=['GET'])
def get_global_model():
    """å®¢æˆ·ç«¯è·å–å½“å‰å…¨å±€æ¨¡å‹"""
    try:
        model_state = server_state.global_model.state_dict()
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable = {}
        for key, tensor in model_state.items():
            serializable[key] = tensor.cpu().numpy().tolist()
        
        return jsonify({
            'success': True,
            'round': server_state.round_num,
            'model': serializable,
            'model_structure': str(server_state.global_model)
        })
    
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/send_update', methods=['POST'])
def receive_update():
    """æ¥æ”¶å®¢æˆ·ç«¯æ¨¡å‹æ›´æ–°"""
    try:
        data = request.json
        
        if not data or 'client_id' not in data or 'model' not in data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦å­—æ®µ: client_id æˆ– model'
            }), 400
        
        client_id = str(data['client_id'])
        client_model = data['model']
        
        print(f"ğŸ“¥ æ”¶åˆ°å®¢æˆ·ç«¯ {client_id} çš„æ›´æ–°")
        
        # æ·»åŠ åˆ°æ›´æ–°åˆ—è¡¨
        if not server_state.add_client_update(client_id, client_model):
            return jsonify({
                'success': False,
                'error': f'å®¢æˆ·ç«¯ {client_id} å·²æäº¤è¿‡æœ¬è½®æ›´æ–°'
            }), 400
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°èšåˆé˜ˆå€¼
        min_clients = config.get("server.min_clients", 2)
        if len(server_state.client_updates) >= min_clients:
            print(f"ğŸ¯ è¾¾åˆ°èšåˆæ¡ä»¶ ({len(server_state.client_updates)}/{min_clients} å®¢æˆ·ç«¯)")
            
            # æ‰§è¡Œè”é‚¦å¹³å‡
            if server_state.federated_average():
                # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                checkpoint_interval = config.get("server.checkpoint_interval", 5)
                if server_state.round_num % checkpoint_interval == 0:
                    server_state.save_checkpoint()
                
                # é‡ç½®è½®æ¬¡çŠ¶æ€
                server_state.reset_round()
                
                return jsonify({
                    'success': True,
                    'message': f'è½®æ¬¡ {server_state.round_num} èšåˆå®Œæˆ',
                    'round_completed': True,
                    'new_round': server_state.round_num
                })
        
        return jsonify({
            'success': True,
            'message': f'æ›´æ–°å·²æ¥æ”¶ï¼Œç­‰å¾…æ›´å¤šå®¢æˆ·ç«¯ ({len(server_state.client_updates)}/{min_clients})',
            'round_completed': False
        })
    
    except Exception as e:
        print(f"âŒ å¤„ç†å®¢æˆ·ç«¯æ›´æ–°å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/server_info', methods=['GET'])
def server_info():
    """è·å–è¯¦ç»†æœåŠ¡å™¨ä¿¡æ¯"""
    model_size = sum(p.numel() for p in server_state.global_model.parameters())
    
    return jsonify({
        "server_config": config.config,
        "current_round": server_state.round_num,
        "active_clients": len(server_state.client_ids),
        "pending_updates": len(server_state.client_updates),
        "model_statistics": {
            "total_parameters": model_size,
            "trainable_parameters": sum(p.numel() for p in server_state.global_model.parameters() if p.requires_grad)
        },
        "checkpoints": {
            "save_path": str(server_state.save_path),
            "latest_round": server_state.round_num
        }
    })

# å¯åŠ¨æœåŠ¡å™¨
if __name__ == '__main__':
    host = config.get("server.host", "0.0.0.0")
    port = config.get("server.port", 5002)
    
    print("=" * 60)
    print("è”é‚¦å­¦ä¹ æœåŠ¡å™¨ - ç³–å°¿ç—…è§†ç½‘è†œç—…å˜æ£€æµ‹")
    print("=" * 60)
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜è·¯å¾„: {server_state.save_path}")
    print(f"ğŸ¤– æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in server_state.global_model.parameters()):,}")
    print(f"ğŸ”§ é…ç½®: æœ€å°‘ {config.get('server.min_clients', 2)} ä¸ªå®¢æˆ·ç«¯è§¦å‘èšåˆ")
    print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: http://{host}:{port}")
    print("=" * 60)
    
    app.run(host=host, port=port, debug=False)
