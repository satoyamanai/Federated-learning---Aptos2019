import requests
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import os
import time
import json
import traceback
from typing import Dict, Tuple, List
import random
from PIL import Image

# FIXED: è®¾ç½®éšæœºç§å­
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    if torch.backends.mps.is_available():
        torch.mps.manual_seed(seed)

set_seed(42)

# ==================== é…ç½® ====================

CLIENT_ID = 4  
SERVER_URL = "http://localhost:5002"
DATASET_PATH = "/Users/yamanaisato/Desktop/Aptos2019"

# ==================== ç®€åŒ–æ¨¡å‹ï¼ˆä¸æœåŠ¡å™¨åŒ¹é…ï¼‰ ====================

class SimpleDiabeticRetinopathyModel(nn.Module):
    """ä¸æœåŠ¡å™¨å®Œå…¨ä¸€è‡´çš„æ¨¡å‹"""
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(128, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 5)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# ==================== æ•°æ®é›†ç±»ï¼ˆå·²ä¿®å¤ï¼‰ ====================
class APTOSDataset(Dataset):
    """åŠ è½½å’Œå¤„ç†APTOSå›¾åƒ - ä½¿ç”¨PILåŠ è½½å›¾åƒ"""
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.transform = transform
        self.image_paths = dataframe['filename'].tolist()
        self.labels = dataframe['diagnosis'].tolist()
    
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        try:
            # FIXED: ä½¿ç”¨PILåŠ è½½å›¾åƒ
            img = Image.open(img_path).convert('RGB')
            
            # FIXED: åº”ç”¨transformï¼ˆtransformåº”å¤„ç†PIL Imageï¼‰
            if self.transform:
                img = self.transform(img)
            
            return img, torch.tensor(label, dtype=torch.long)
            
        except Exception as e:
            print(f"å¤„ç†å›¾åƒæ—¶å‡ºé”™ {img_path}: {e}")
            # è¿”å›ç©ºç™½å›¾åƒä½œä¸ºå®¹é”™
            blank_img = torch.zeros((3, 224, 224), dtype=torch.float32)
            return blank_img, torch.tensor(label, dtype=torch.long)

# ==================== è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯ ====================
class FederatedClient:
    def __init__(self, client_id: int, num_local_epochs: int = 2):
        self.client_id = client_id
        self.server_url = SERVER_URL
        self.num_local_epochs = num_local_epochs
        self.current_round = 0  # è·Ÿè¸ªå½“å‰è½®æ¬¡
        
        # è®¾å¤‡é…ç½®
        self.device = self._get_device()
        print(f"ğŸ–¥ï¸  å®¢æˆ·ç«¯ {client_id} ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = SimpleDiabeticRetinopathyModel().to(self.device)
        
        # åŠ è½½æ•°æ®
        self.train_loader, self.data_info = self._prepare_local_data()
        
        print(f"âœ… å®¢æˆ·ç«¯ {client_id} åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ•°æ®é‡: {self.data_info['total_samples']} å›¾åƒ")
        print(f"   ç±»åˆ«åˆ†å¸ƒ: {self.data_info['class_distribution']}")
        print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
    
    def _get_device(self) -> torch.device:
        """è·å–æœ€ä½³è®¡ç®—è®¾å¤‡"""
        if torch.backends.mps.is_available():
            return torch.device("mps")
        elif torch.cuda.is_available():
            return torch.device("cuda:0")
        else:
            return torch.device("cpu")
    
    def _prepare_local_data(self) -> Tuple[DataLoader, Dict]:
        """å‡†å¤‡æœ¬åœ°æ•°æ®ï¼Œæ¨¡æ‹ŸéIIDåˆ†å¸ƒ"""
        if not os.path.exists(DATASET_PATH):
            raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {DATASET_PATH}")
        
        train_csv_path = os.path.join(DATASET_PATH, "train.csv")
        if not os.path.exists(train_csv_path):
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {train_csv_path}")
        
        # åŠ è½½æ•°æ®
        train_df = pd.read_csv(train_csv_path)
        
        # æ·»åŠ å®Œæ•´æ–‡ä»¶è·¯å¾„
        train_df["filename"] = train_df["id_code"].apply(
            lambda x: os.path.join(DATASET_PATH, "train_images", f"{x}.png")
        )
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        existing_files = []
        for _, row in train_df.iterrows():
            if os.path.exists(row['filename']):
                existing_files.append(row)
        
        if not existing_files:
            raise FileNotFoundError("æ‰¾ä¸åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
        
        train_df = pd.DataFrame(existing_files)
        print(f"ğŸ“Š æ‰¾åˆ° {len(train_df)} ä¸ªæœ‰æ•ˆå›¾åƒæ–‡ä»¶")
        
        # æ¨¡æ‹ŸéIIDåˆ†å¸ƒ
        if self.client_id == 1:
            condition = train_df['diagnosis'].isin([0, 1])
            subset = train_df[condition]
            if len(subset) > 100:
                client_df = subset.sample(n=100, random_state=42)
            else:
                client_df = subset
        elif self.client_id == 2:
            condition = train_df['diagnosis'] == 2
            subset = train_df[condition]
            if len(subset) > 100:
                client_df = subset.sample(n=100, random_state=43)
            else:
                client_df = subset
        elif self.client_id == 3:
            condition = train_df['diagnosis'] == 3
            subset = train_df[condition]
            if len(subset) > 80:
                client_df = subset.sample(n=80, random_state=44)
            else:
                client_df = subset
        elif self.client_id == 4:
            condition = train_df['diagnosis'] == 4
            subset = train_df[condition]
            if len(subset) > 60:
                client_df = subset.sample(n=60, random_state=45)
            else:
                client_df = subset
        else:
            client_df = train_df.sample(n=100, random_state=46)
        
        print(f"ğŸ“ å®¢æˆ·ç«¯ {self.client_id} åˆ†é…åˆ° {len(client_df)} å¼ å›¾åƒ")
        
        # FIXED: æ­£ç¡®çš„transformé¡ºåº
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.3),
            transforms.RandomRotation(degrees=5),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = APTOSDataset(client_df, transform=transform)
        
        batch_size = min(8, len(dataset))
        data_loader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=0,
            pin_memory=False
        )
        
        # ç»Ÿè®¡ä¿¡æ¯
        class_dist = dict(client_df['diagnosis'].value_counts().sort_index())
        data_info = {
            'total_samples': len(dataset),
            'class_distribution': class_dist,
            'batch_size': batch_size,
            'num_batches': len(data_loader)
        }
        
        return data_loader, data_info
    
    def download_global_model(self) -> bool:
        """ä»æœåŠ¡å™¨ä¸‹è½½å…¨å±€æ¨¡å‹"""
        print(f"â¬‡ï¸  å®¢æˆ·ç«¯ {self.client_id} æ­£åœ¨ä¸‹è½½å…¨å±€æ¨¡å‹...")
        
        try:
            # å°è¯•ä»get_modelç«¯ç‚¹ä¸‹è½½
            response = requests.get(
                f"{self.server_url}/get_model",
                timeout=30,
                headers={'Content-Type': 'application/json'}
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('success', False):
                    print(f"ğŸ“¥ æ”¶åˆ°æœåŠ¡å™¨æ¨¡å‹ï¼Œè½®æ¬¡: {data.get('round', 0)}")
                    
                    # æ£€æŸ¥è½®æ¬¡æ˜¯å¦æ›´æ–°
                    server_round = data.get('round', 0)
                    if server_round != self.current_round:
                        print(f"ğŸ”„ æ›´æ–°å®¢æˆ·ç«¯è½®æ¬¡: {self.current_round} -> {server_round}")
                        self.current_round = server_round
                    
                    # ååºåˆ—åŒ–æ¨¡å‹æƒé‡
                    server_weights = data['model']
                    
                    # è½¬æ¢ä¸ºtorch tensor
                    state_dict = {}
                    for key, value in server_weights.items():
                        tensor = torch.tensor(value, dtype=torch.float32)
                        state_dict[key] = tensor
                    
                    # åŠ è½½æƒé‡
                    self.model.load_state_dict(state_dict, strict=True)
                    self.model.to(self.device)
                    
                    print(f"âœ… æˆåŠŸåŠ è½½å…¨å±€æ¨¡å‹")
                    print(f"   æ¨¡å‹é”®å€¼æ•°é‡: {len(state_dict)}")
                    
                    return True
                else:
                    error_msg = data.get('error', 'æœªçŸ¥é”™è¯¯')
                    print(f"âŒ æœåŠ¡å™¨è¿”å›é”™è¯¯: {error_msg}")
                    return False
            else:
                print(f"âŒ æœåŠ¡å™¨å“åº”é”™è¯¯: {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text[:200]}")
                return False
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")
            return False
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            traceback.print_exc()
            return False
    
    def local_train(self) -> Tuple[float, float]:
        """æœ¬åœ°è®­ç»ƒæ¨¡å‹"""
        print(f"ğŸ¯ å®¢æˆ·ç«¯ {self.client_id} å¼€å§‹æœ¬åœ°è®­ç»ƒ...")
        
        # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼
        self.model.train()
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)
        
        # è®­ç»ƒç»Ÿè®¡
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        
        for epoch in range(self.num_local_epochs):
            epoch_loss = 0.0
            epoch_correct = 0
            epoch_samples = 0
            
            for batch_idx, (images, labels) in enumerate(self.train_loader):
                # æ£€æŸ¥æ•°æ®ç±»å‹
                if not isinstance(images, torch.Tensor):
                    print(f"âš ï¸ è­¦å‘Š: imagesç±»å‹å¼‚å¸¸: {type(images)}")
                    continue
                
                # ç§»åˆ°è®¾å¤‡
                images = images.to(self.device, non_blocking=True)
                labels = labels.to(self.device, non_blocking=True)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                outputs = self.model(images)
                loss = criterion(outputs, labels)
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                # ç»Ÿè®¡
                batch_size = images.size(0)
                epoch_loss += loss.item() * batch_size
                _, predicted = torch.max(outputs, 1)
                epoch_correct += (predicted == labels).sum().item()
                epoch_samples += batch_size
                
                # æ¯2ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if batch_idx % 2 == 0 or batch_idx == len(self.train_loader) - 1:
                    batch_acc = (predicted == labels).sum().item() / max(1, batch_size)
                    print(f"   æ‰¹æ¬¡ {batch_idx}/{len(self.train_loader)}: "
                          f"Loss={loss.item():.4f}, Acc={batch_acc:.4f}")
            
            # æœ¬è½®ç»Ÿè®¡
            epoch_avg_loss = epoch_loss / max(1, epoch_samples)
            epoch_accuracy = epoch_correct / max(1, epoch_samples)
            
            print(f"   Epoch {epoch+1}/{self.num_local_epochs}: "
                  f"Loss={epoch_avg_loss:.4f}, Acc={epoch_accuracy:.4f}")
            
            total_loss += epoch_loss
            total_correct += epoch_correct
            total_samples += epoch_samples
        
        # æ€»ä½“ç»Ÿè®¡
        avg_loss = total_loss / max(1, total_samples)
        avg_accuracy = total_correct / max(1, total_samples)
        
        print(f"âœ… å®¢æˆ·ç«¯ {self.client_id} è®­ç»ƒå®Œæˆ:")
        print(f"   å¹³å‡Loss: {avg_loss:.4f}")
        print(f"   å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")
        
        return avg_loss, avg_accuracy
    
    def send_update(self) -> bool:
        """å‘é€æœ¬åœ°æ›´æ–°åˆ°æœåŠ¡å™¨"""
        print(f"â¬†ï¸  å®¢æˆ·ç«¯ {self.client_id} æ­£åœ¨å‘é€æ›´æ–°...")
        
        try:
            # è·å–æ¨¡å‹æƒé‡
            self.model.to('cpu')
            model_state = self.model.state_dict()
            
            # æ‰“å°æ¨¡å‹é”®å€¼ç”¨äºè°ƒè¯•
            print("ğŸ” æ¨¡å‹æƒé‡é”®å€¼:")
            key_list = list(model_state.keys())
            for i, key in enumerate(key_list[:3]):
                shape = list(model_state[key].shape)
                print(f"  {i+1}. {key}: {shape}")
            if len(key_list) > 3:
                print(f"  ... è¿˜æœ‰ {len(key_list)-3} ä¸ªé”®")
            
            # åºåˆ—åŒ–ä¸ºå¯JSONä¼ è¾“çš„æ ¼å¼
            serializable = {}
            for key, tensor in model_state.items():
                # ç¡®ä¿æ˜¯float32å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
                if tensor.is_floating_point():
                    tensor = tensor.to(torch.float32)
                serializable[key] = tensor.cpu().numpy().tolist()
            
            # å‡†å¤‡å‘é€æ•°æ®
            data = {
                'client_id': str(self.client_id),
                'model': serializable,
                'data_size': self.data_info['total_samples'],
                'current_round': self.current_round,  # å‘é€å½“å‰è½®æ¬¡
                'timestamp': time.time()
            }
            
            print(f"ğŸ“¤ å‘é€æ•°æ®å¤§å°: {len(str(data))} å­—ç¬¦")
            print(f"ğŸ“¤ æ¨¡å‹é”®å€¼æ•°é‡: {len(serializable)}")
            
            # å‘é€åˆ°æœåŠ¡å™¨
            response = requests.post(
                f"{self.server_url}/send_update",
                json=data,
                timeout=60,
                headers={'Content-Type': 'application/json'}
            )
            
            print(f"ğŸ“¥ æœåŠ¡å™¨å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"ğŸ“¥ æœåŠ¡å™¨å“åº”: {result}")
                
                if result.get('success', False):
                    message = result.get('message', 'æ›´æ–°æˆåŠŸ')
                    print(f"âœ… {message}")
                    
                    # æ›´æ–°è½®æ¬¡ä¿¡æ¯
                    if result.get('round_completed', False):
                        new_round = result.get('new_round', self.current_round + 1)
                        print(f"ğŸ‰ è½®æ¬¡ {new_round} èšåˆå®Œæˆ!")
                        self.current_round = new_round
                    
                    return True
                else:
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    print(f"âŒ æœåŠ¡å™¨å¤„ç†å¤±è´¥: {error_msg}")
                    return False
            else:
                print(f"âŒ æœåŠ¡å™¨å“åº”é”™è¯¯: {response.status_code}")
                print(f"ğŸ“¥ å“åº”å†…å®¹: {response.text[:200]}")
                return False
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")
            return False
        except Exception as e:
            print(f"âŒ å‘é€æ›´æ–°å¤±è´¥: {e}")
            traceback.print_exc()
            return False
        finally:
            # ç¡®ä¿æ¨¡å‹å›åˆ°æ­£ç¡®çš„è®¾å¤‡
            self.model.to(self.device)
    
    def participate(self, num_rounds=3):
        """å‚ä¸è”é‚¦å­¦ä¹ è¿‡ç¨‹"""
        print("=" * 60)
        print(f"ğŸ¤– è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯ {self.client_id}")
        print(f"   æœåŠ¡å™¨: {self.server_url}")
        print(f"   å‚ä¸è½®æ¬¡: {num_rounds}")
        print("=" * 60)
        
        for round_num in range(num_rounds):
            print(f"\n{'='*40}")
            print(f"ğŸ”„ ç¬¬ {round_num + 1}/{num_rounds} è½®")
            print(f"{'='*40}")
            
            # 1. è·å–å…¨å±€æ¨¡å‹
            print(f"ğŸ”½ æ­¥éª¤1: ä¸‹è½½å…¨å±€æ¨¡å‹")
            if not self.download_global_model():
                print("â³ ä¸‹è½½å¤±è´¥ï¼Œç­‰å¾…10ç§’åé‡è¯•...")
                time.sleep(10)
                if not self.download_global_model():
                    print("âŒ å†æ¬¡ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
                    continue
            
            # 2. æœ¬åœ°è®­ç»ƒ
            print(f"ğŸ¯ æ­¥éª¤2: æœ¬åœ°è®­ç»ƒ")
            try:
                loss, accuracy = self.local_train()
                print(f"ğŸ“Š è®­ç»ƒç»“æœ - Loss: {loss:.4f}, Acc: {accuracy:.4f}")
            except Exception as e:
                print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
                traceback.print_exc()
                continue
            
            # 3. å‘é€æ›´æ–°
            print(f"â¬†ï¸  æ­¥éª¤3: å‘é€æ›´æ–°")
            max_retries = 3
            for retry in range(max_retries):
                if self.send_update():
                    break
                elif retry < max_retries - 1:
                    wait_time = 5 * (retry + 1)
                    print(f"â³ å‘é€å¤±è´¥ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print("âŒ å‘é€æ›´æ–°å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
            
            # 4. ç­‰å¾…ä¸‹ä¸€è½®
            if round_num < num_rounds - 1:
                wait_time = 10
                print(f"\nâ³ ç­‰å¾… {wait_time} ç§’è¿›å…¥ä¸‹ä¸€è½®...")
                time.sleep(wait_time)
        
        print("\n" + "=" * 60)
        print(f"ğŸ å®¢æˆ·ç«¯ {self.client_id} å®Œæˆæ‰€æœ‰è”é‚¦å­¦ä¹ è½®æ¬¡!")
        print("=" * 60)

# ==================== è¾…åŠ©å‡½æ•° ====================
def check_server_health() -> bool:
    """æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€"""
    try:
        print("ğŸ” æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€...")
        response = requests.get(f"{SERVER_URL}/", timeout=10)
        
        if response.status_code == 200:
            server_info = response.json()
            print(f"âœ… æœåŠ¡å™¨æ­£å¸¸è¿è¡Œ")
            print(f"   çŠ¶æ€: {server_info.get('status', 'unknown')}")
            print(f"   å½“å‰è½®æ¬¡: {server_info.get('round', 0)}")
            print(f"   è¿è¡Œæ—¶é—´: {server_info.get('uptime_seconds', 0)} ç§’")
            return True
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
        print("ğŸ’¡ è¯·ç¡®ä¿æœåŠ¡å™¨å·²å¯åŠ¨: python server.py")
        return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æœåŠ¡å™¨æ—¶å‡ºé”™: {e}")
        return False

def check_dataset() -> bool:
    """æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨"""
    print("ğŸ” æ£€æŸ¥æ•°æ®é›†...")
    
    required_files = [
        ("train.csv", os.path.join(DATASET_PATH, "train.csv")),
        ("train_imagesç›®å½•", os.path.join(DATASET_PATH, "train_images"))
    ]
    
    all_ok = True
    for file_name, file_path in required_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_name}: å­˜åœ¨")
        else:
            print(f"âŒ {file_name}: ä¸å­˜åœ¨ ({file_path})")
            all_ok = False
    
    if all_ok:
        try:
            csv_path = os.path.join(DATASET_PATH, "train.csv")
            df = pd.read_csv(csv_path)
            print(f"âœ… CSVæ–‡ä»¶æœ‰æ•ˆï¼ŒåŒ…å« {len(df)} è¡Œ")
            print(f"   ç±»åˆ«åˆ†å¸ƒ:")
            print(df['diagnosis'].value_counts().sort_index())
            return True
        except Exception as e:
            print(f"âŒ è¯»å–CSVå¤±è´¥: {e}")
            return False
    else:
        return False

# ==================== ä¸»å‡½æ•° ====================
def main():
    print("\n" + "=" * 60)
    print("è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯ - APTOSç³–å°¿ç—…è§†ç½‘è†œç—…å˜æ£€æµ‹")
    print("=" * 60)
    print(f"å®¢æˆ·ç«¯ID: {CLIENT_ID}")
    print(f"æœåŠ¡å™¨: {SERVER_URL}")
    print(f"æ•°æ®é›†è·¯å¾„: {DATASET_PATH}")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ä¾èµ–
    print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–...")
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
        if torch.backends.mps.is_available():
            print("âœ… Apple Silicon (MPS) å¯ç”¨")
        elif torch.cuda.is_available():
            print("âœ… CUDA å¯ç”¨")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        print("ğŸ’¡ è¯·è¿è¡Œ: pip install torch torchvision")
        return
    
    # 2. æ£€æŸ¥æ•°æ®é›†
    print("\nğŸ“ æ£€æŸ¥æ•°æ®é›†...")
    if not check_dataset():
        print("âŒ æ•°æ®é›†æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶")
        return
    
    # 3. æ£€æŸ¥æœåŠ¡å™¨
    print("\nğŸŒ æ£€æŸ¥æœåŠ¡å™¨è¿æ¥...")
    if not check_server_health():
        print("âŒ æœåŠ¡å™¨æ£€æŸ¥å¤±è´¥")
        return
    
    # 4. åˆ›å»ºå¹¶è¿è¡Œå®¢æˆ·ç«¯
    print("\nğŸš€ å¯åŠ¨è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯...")
    try:
        client = FederatedClient(
            client_id=CLIENT_ID,
            num_local_epochs=1  # æµ‹è¯•ç”¨1ä¸ªepoch
        )
        
        # å‚ä¸è”é‚¦å­¦ä¹ 
        client.participate(num_rounds=2)  # æµ‹è¯•ç”¨2è½®
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å®¢æˆ·ç«¯è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®¢æˆ·ç«¯è¿è¡Œå‡ºé”™: {e}")
        traceback.print_exc()
        print("\nğŸ’¡ è°ƒè¯•å»ºè®®:")
        print("1. æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ: python server.py")
        print("2. æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("3. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯")

if __name__ == '__main__':
    main()
